{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate Library and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bobi/opt/anaconda3/envs/sentiment_analysis/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "from typing import Union\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentPredictor:\n",
    "    def __init__(self) -> None:\n",
    "        # set bert model names\n",
    "        bert_model_names = [\n",
    "            'mdhugol/indonesia-bert-sentiment-classification',\n",
    "            'poerwiyanto/bert-base-indonesian-522M-finetuned-sentiment',\n",
    "            'hilmansw/indobert-finetuned-sentiment-happiness-index'\n",
    "        ]\n",
    "\n",
    "        # set roberta model names\n",
    "        roberta_model_names = [\n",
    "            'ayameRushia/roberta-base-indonesian-1.5G-sentiment-analysis-smsa'\n",
    "        ]\n",
    "\n",
    "        # create sentiment pipelines\n",
    "        self.sentiment_pipelines = {}\n",
    "        self.model_names = {}\n",
    "\n",
    "        for model_name in bert_model_names:\n",
    "            arch = 'bert'\n",
    "            name = model_name.split('/')[0]\n",
    "            model_pipeline = self.load_sentiment_pipeline(model_name, arch)\n",
    "            self.sentiment_pipelines[name] = model_pipeline\n",
    "            self.model_names[name] = arch\n",
    "\n",
    "        for model_name in roberta_model_names:\n",
    "            arch = 'roberta'\n",
    "            name = model_name.split('/')[0]\n",
    "            model_pipeline = self.load_sentiment_pipeline(model_name, arch)\n",
    "            self.sentiment_pipelines[name] = model_pipeline\n",
    "            self.model_names[name] = arch\n",
    "\n",
    "    def predict(self, text:Union[str,list], model_name:str):\n",
    "        if model_name not in self.sentiment_pipelines.keys():\n",
    "            print('Please select model name from this list {}'.format(list(self.sentiment_pipelines.keys())))\n",
    "            return\n",
    "        \n",
    "        model_arch = self.model_names.get(model_name)\n",
    "        model_pipeline = self.sentiment_pipelines.get(model_name)\n",
    "\n",
    "        predictions = self.postprocess_label(\n",
    "            predictions = model_pipeline(text),\n",
    "            model_name = model_name,\n",
    "            model_arch = model_arch\n",
    "        )\n",
    "\n",
    "        return predictions\n",
    "        \n",
    "    @staticmethod\n",
    "    def load_sentiment_pipeline(model_name:str, model_arch:str):\n",
    "        if model_arch == 'bert':\n",
    "            tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "            model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "        elif model_arch == 'roberta':\n",
    "            tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "            model = RobertaForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "        sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "        return sentiment_pipeline\n",
    "    \n",
    "    @staticmethod\n",
    "    def postprocess_label(predictions:list, model_name:str, model_arch:str):\n",
    "        bert_labels_1 = {'LABEL_0' : 'positive', 'LABEL_1': 'neutral', 'LABEL_2': 'negative'}\n",
    "        bert_labels_2 = {'positif' : 'positive', 'netral': 'neutral', 'negatif': 'negative'}\n",
    "\n",
    "        for i, prediction in enumerate(predictions.copy()):\n",
    "            if model_arch == 'bert' and model_name in ['mdhugol', 'poerwiyanto']:\n",
    "                predictions[i]['label'] = bert_labels_1.get(prediction['label'])\n",
    "            if model_arch == 'bert' and model_name in ['hilmansw']:\n",
    "                predictions[i]['label'] = bert_labels_2.get(prediction['label'])\n",
    "            elif model_arch == 'roberta':\n",
    "                predictions[i]['label'] = prediction['label'].lower()\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "sentiment_predictor = SentimentPredictor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis: 116it [00:20,  5.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# get model names\n",
    "model_names = list(sentiment_predictor.model_names.keys())\n",
    "\n",
    "# load data\n",
    "csv_path = './dataset/single-word-cases.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# create column data\n",
    "for model_name in model_names:\n",
    "    if model_name+'_pred' not in df.columns:\n",
    "        df[model_name+'_pred'] = ['']*len(df)\n",
    "    if model_name+'_conf' not in df.columns:\n",
    "        df[model_name+'_conf'] = [0.]*len(df)\n",
    "\n",
    "# predict sentiment\n",
    "for i, row in tqdm(df.copy().iterrows(), desc='Sentiment Analysis', ncols=100):\n",
    "    sentence = row['sentence']\n",
    "    for model_name in model_names:\n",
    "        if row[model_name+'_pred'] != '':\n",
    "            continue\n",
    "        result = sentiment_predictor.predict(sentence, model_name)\n",
    "        df.at[i, model_name+'_pred'] = result[0]['label']\n",
    "        df.at[i, model_name+'_conf'] = result[0]['score']\n",
    "\n",
    "# save dataframe to csv\n",
    "df.to_csv(csv_path, index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test and Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mdhugol\n",
      "====================\n",
      "> Weighted F1 score\n",
      "0.5560419579169914\n",
      "> Per class F1 score\n",
      "[0.36594203 0.58461538 0.5875    ]\n",
      "> Confusion matrix\n",
      "[[101   5   1]\n",
      " [326 266  34]\n",
      " [ 18  13  47]]\n",
      "> Confusion matrix (normalized)\n",
      "[[0.94392523 0.04672897 0.00934579]\n",
      " [0.52076677 0.42492013 0.0543131 ]\n",
      " [0.23076923 0.16666667 0.6025641 ]]\n",
      "\n",
      "poerwiyanto\n",
      "====================\n",
      "> Weighted F1 score\n",
      "0.24644780032747832\n",
      "> Per class F1 score\n",
      "[0.069869   0.29499323 0.10280374]\n",
      "> Confusion matrix\n",
      "[[  8   2  97]\n",
      " [ 77 109 434]\n",
      " [ 37   8  33]]\n",
      "> Confusion matrix (normalized)\n",
      "[[0.07476636 0.01869159 0.90654206]\n",
      " [0.12419355 0.17580645 0.7       ]\n",
      " [0.47435897 0.1025641  0.42307692]]\n",
      "\n",
      "hilmansw\n",
      "====================\n",
      "> Weighted F1 score\n",
      "0.7439838530000468\n",
      "> Per class F1 score\n",
      "[0.42446043 0.85625774 0.25      ]\n",
      "> Confusion matrix\n",
      "[[ 59  56   3]\n",
      " [ 92 691   6]\n",
      " [  9  78  16]]\n",
      "> Confusion matrix (normalized)\n",
      "[[0.5        0.47457627 0.02542373]\n",
      " [0.1166033  0.87579214 0.00760456]\n",
      " [0.08737864 0.75728155 0.15533981]]\n",
      "\n",
      "ayameRushia\n",
      "====================\n",
      "> Weighted F1 score\n",
      "0.2684353222372659\n",
      "> Per class F1 score\n",
      "[0.27742749 0.25117371 0.38866397]\n",
      "> Confusion matrix\n",
      "[[110   1   3]\n",
      " [529 107  99]\n",
      " [ 40   9  48]]\n",
      "> Confusion matrix (normalized)\n",
      "[[0.96491228 0.00877193 0.02631579]\n",
      " [0.71972789 0.14557823 0.13469388]\n",
      " [0.41237113 0.09278351 0.49484536]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# open labeled csv\n",
    "label_csv_path = './dataset/gsheet-fw-cases.csv'\n",
    "label_df = pd.read_csv(label_csv_path)\n",
    "\n",
    "# open prediction csv\n",
    "pred_csv_path = './dataset/fw-cases.csv'\n",
    "pred_df = pd.read_csv(pred_csv_path, sep=';')\n",
    "\n",
    "# join table\n",
    "final_df = label_df.copy()\n",
    "for col in pred_df.columns:\n",
    "    # skip sentence and case column\n",
    "    if col in ['sentence', 'case']:\n",
    "        continue\n",
    "    # join column\n",
    "    final_df[col] = pred_df[col].copy()\n",
    "\n",
    "# clean label side of data\n",
    "def clean_label_side(final_df):\n",
    "    # clean data: drop 'no' and 'case' column\n",
    "    final_df.drop(columns=['no', 'case'], inplace=True)\n",
    "\n",
    "    # clean data: drop skipped gt label\n",
    "    final_df.drop(\n",
    "        final_df.loc[\n",
    "            final_df.label_adam.str.contains('-') |\n",
    "            final_df.label_anthony.str.contains('-') |\n",
    "            final_df.label_yoshua.str.contains('-')\n",
    "        ].index,\n",
    "        inplace=True\n",
    "    )\n",
    "    final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # clean data: drop null gt label\n",
    "    final_df.drop(\n",
    "        final_df.loc[\n",
    "            final_df.label_adam.isna() |\n",
    "            final_df.label_anthony.isna() |\n",
    "            final_df.label_yoshua.isna()\n",
    "        ].index,\n",
    "        inplace=True\n",
    "    )\n",
    "    final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # aggregate data & drop draw label votes\n",
    "    def aggregate_sentiment(row):\n",
    "        sentiments = {}\n",
    "        for key, val in row.items():\n",
    "            if 'label_' not in key:\n",
    "                continue\n",
    "            if key not in sentiments.keys():\n",
    "                sentiments[val] = 1\n",
    "            else:\n",
    "                sentiments[val] += 1\n",
    "            draw = False\n",
    "\n",
    "        sorted_sentiments = sorted(sentiments.items(), key=lambda x:x[1], reverse=True)\n",
    "        sentiment = sorted_sentiments[0][0]\n",
    "        if len(sorted_sentiments) > 1:\n",
    "            if sorted_sentiments[0][1] == sorted_sentiments[1][1]:\n",
    "                draw = True\n",
    "\n",
    "        return sentiment, draw\n",
    "\n",
    "    label_final = []\n",
    "    draw_index = []\n",
    "    for i, row in final_df.iterrows():\n",
    "        sentiment, draw = aggregate_sentiment(row)\n",
    "        label_final.append(sentiment)\n",
    "        if draw:\n",
    "            draw_index.append(i)\n",
    "    final_df['label_final'] = label_final\n",
    "    final_df.drop(draw_index, inplace=True)\n",
    "    final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "final_df = clean_label_side(final_df)\n",
    "\n",
    "# analyze accuracy per model\n",
    "CONFIDENCE_THRESHOLD = 0.8\n",
    "\n",
    "def analyze_model(final_df, confidence_threshold):\n",
    "    # get model names\n",
    "    model_names = [col.replace('_pred', '') for col in final_df.columns if '_pred' in col]\n",
    "\n",
    "    # iterate models\n",
    "    for model_name in model_names:\n",
    "        # copy data for specific model\n",
    "        model_df = final_df[['label_final', model_name+'_pred', model_name+'_conf']].copy()\n",
    "\n",
    "        # drop low confidence predictions\n",
    "        model_df.drop(\n",
    "            model_df.loc[\n",
    "                model_df[model_name+'_conf'] < confidence_threshold\n",
    "            ].index,\n",
    "            inplace=True\n",
    "        )\n",
    "\n",
    "        # analyze model\n",
    "        print(model_name + '\\n' + '='*20)\n",
    "        labels = model_df['label_final'].to_list()\n",
    "        preds = model_df[model_name+'_pred']\n",
    "        print('> Weighted F1 score')\n",
    "        print(f1_score(labels, preds, average='weighted'))\n",
    "        print('> Per class F1 score')\n",
    "        print(f1_score(labels, preds, average=None))\n",
    "        print('> Confusion matrix')\n",
    "        print(confusion_matrix(labels, preds, labels=['negative', 'neutral', 'positive']))\n",
    "        print('> Confusion matrix (normalized)')\n",
    "        print(confusion_matrix(labels, preds, labels=['negative', 'neutral', 'positive'], normalize='true'))\n",
    "        print()\n",
    "\n",
    "analyze_model(final_df, CONFIDENCE_THRESHOLD)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
