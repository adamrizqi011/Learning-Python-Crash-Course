{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate Library and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "from typing import Union\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentPredictor:\n",
    "    def __init__(self) -> None:\n",
    "        # set bert model names\n",
    "        bert_model_names = [\n",
    "            'mdhugol/indonesia-bert-sentiment-classification',\n",
    "            'poerwiyanto/bert-base-indonesian-522M-finetuned-sentiment',\n",
    "            'hilmansw/indobert-finetuned-sentiment-happiness-index'\n",
    "        ]\n",
    "\n",
    "        # set roberta model names\n",
    "        roberta_model_names = [\n",
    "            'ayameRushia/roberta-base-indonesian-1.5G-sentiment-analysis-smsa'\n",
    "        ]\n",
    "\n",
    "        # create sentiment pipelines\n",
    "        self.sentiment_pipelines = {}\n",
    "        self.model_names = {}\n",
    "       \n",
    "        for model_name in bert_model_names:\n",
    "            arch = 'bert'\n",
    "            name = model_name.split('/')[0]\n",
    "            model_pipeline = self.load_sentiment_pipeline(model_name, arch)\n",
    "            self.sentiment_pipelines[name] = model_pipeline\n",
    "            self.model_names[name] = arch\n",
    "\n",
    "        for model_name in roberta_model_names:\n",
    "            arch = 'roberta'\n",
    "            name = model_name.split('/')[0]\n",
    "            model_pipeline = self.load_sentiment_pipeline(model_name, arch)\n",
    "            self.sentiment_pipelines[name] = model_pipeline\n",
    "            self.model_names[name] = arch\n",
    "\n",
    "    def predict(self, text:Union[str,list], model_name:str):\n",
    "        if model_name not in self.sentiment_pipelines.keys():\n",
    "            print('Please select model name from this list {}'.format(list(self.sentiment_pipelines.keys())))\n",
    "            return\n",
    "        \n",
    "        model_arch = self.model_names.get(model_name)\n",
    "        model_pipeline = self.sentiment_pipelines.get(model_name)\n",
    "        predictions = self.postprocess_label(\n",
    "            predictions = model_pipeline(text),\n",
    "            model_name = model_name,\n",
    "            model_arch = model_arch\n",
    "        )\n",
    "\n",
    "        return predictions\n",
    "        \n",
    "    @staticmethod\n",
    "    def load_sentiment_pipeline(model_name:str, model_arch:str):\n",
    "        if model_arch == 'bert':\n",
    "            tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "            model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "        elif model_arch == 'roberta':\n",
    "            tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "            model = RobertaForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "        sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "        return sentiment_pipeline\n",
    "\n",
    "    @staticmethod\n",
    "    def postprocess_label(predictions:list, model_name:str, model_arch:str):\n",
    "        bert_labels_1 = {'LABEL_0' : 'positive', 'LABEL_1': 'neutral', 'LABEL_2': 'negative'}\n",
    "        bert_labels_2 = {'positif' : 'positive', 'netral': 'neutral', 'negatif': 'negative'}\n",
    "\n",
    "        for i, prediction in enumerate(predictions.copy()):\n",
    "            if model_arch == 'bert' and model_name in ['mdhugol', 'poerwiyanto']:\n",
    "                predictions[i]['label'] = bert_labels_1.get(prediction['label'])\n",
    "            if model_arch == 'bert' and model_name in ['hilmansw']:\n",
    "                predictions[i]['label'] = bert_labels_2.get(prediction['label'])\n",
    "            elif model_arch == 'roberta':\n",
    "                predictions[i]['label'] = prediction['label'].lower()\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "sentiment_predictor = SentimentPredictor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis: 116it [00:33,  3.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# get model names\n",
    "model_names = list(sentiment_predictor.model_names.keys())\n",
    "\n",
    "# load data\n",
    "csv_path = './dataset/single-word.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# create column data\n",
    "for model_name in model_names:\n",
    "    if model_name+'_pred' not in df.columns:\n",
    "        df[model_name+'_pred'] = ['']*len(df)\n",
    "    if model_name+'_conf' not in df.columns:\n",
    "        df[model_name+'_conf'] = [0.]*len(df)\n",
    "\n",
    "# predict sentiment\n",
    "for i, row in tqdm(df.copy().iterrows(), desc='Sentiment Analysis', ncols=100):\n",
    "    sentence = row['sentence']\n",
    "    for model_name in model_names:\n",
    "        if row[model_name+'_pred'] != '':\n",
    "            continue\n",
    "        result = sentiment_predictor.predict(sentence, model_name)\n",
    "        df.at[i, model_name+'_pred'] = result[0]['label']\n",
    "        df.at[i, model_name+'_conf'] = result[0]['score'] \n",
    "        \n",
    "# save dataframe to csv\n",
    "df.to_csv(csv_path, index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test and Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36685386685386684\n",
      "0.023798899300907336\n",
      "0.9554341133004925\n",
      "0.002415458937198068\n"
     ]
    }
   ],
   "source": [
    "# open labeled csv\n",
    "label_csv_path = './dataset/g-sheet-single-word.csv'\n",
    "label_df = pd.read_csv(label_csv_path)\n",
    "# display(label_df)\n",
    "# open prediction csv\n",
    "pred_csv_path = './dataset/single-word.csv'\n",
    "pred_df = pd.read_csv(pred_csv_path, sep=';')\n",
    "\n",
    "# join table\n",
    "final_df = label_df.copy()\n",
    "for col in pred_df.columns:\n",
    "    # skip sentence and case column\n",
    "    if col in ['sentence', 'case']:\n",
    "        continue\n",
    "    # join column\n",
    "    final_df[col] = pred_df[col].copy()\n",
    "\n",
    "# clean label side of data\n",
    "def clean_label_side(final_df):\n",
    "    # clean data: drop 'no' and 'case' column\n",
    "    final_df.drop(columns=['no', 'case'], inplace=True)\n",
    "  \n",
    "    # clean data: drop skipped gt label\n",
    "    final_df.drop(\n",
    "        final_df.loc[\n",
    "            final_df.label_adam.str.contains('-') |\n",
    "            final_df.label_anthony.str.contains('-') |\n",
    "            final_df.label_yoshua.str.contains('-')\n",
    "        ].index,\n",
    "        inplace=True\n",
    "    )\n",
    "    final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # clean data: drop null gt label\n",
    "    final_df.drop(\n",
    "        final_df.loc[\n",
    "            final_df.label_adam.isna() |\n",
    "            final_df.label_anthony.isna() |\n",
    "            final_df.label_yoshua.isna()\n",
    "        ].index,\n",
    "        inplace=True\n",
    "    )\n",
    "    final_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # aggregate data & drop draw label votes\n",
    "    def aggregate_sentiment(row):\n",
    "        sentiments = {}\n",
    "        for key, val in row.items():\n",
    "            if 'label_' not in key:\n",
    "                continue\n",
    "            if key not in sentiments.keys():\n",
    "                sentiments[val] = 1\n",
    "            else:\n",
    "                sentiments[val] += 1\n",
    "            draw = False\n",
    "        sorted_sentiments = sorted(sentiments.items(), key=lambda x:x[1], reverse=True)\n",
    "        sentiment = sorted_sentiments[0][0]\n",
    "        if len(sorted_sentiments) > 1:\n",
    "            if sorted_sentiments[0][1] == sorted_sentiments[1][1]:\n",
    "                draw = True\n",
    "\n",
    "        return sentiment, draw\n",
    "\n",
    "    label_final = []\n",
    "    draw_index = []\n",
    "    for i, row in final_df.iterrows():\n",
    "        sentiment, draw = aggregate_sentiment(row)\n",
    "        label_final.append(sentiment)\n",
    "        if draw:\n",
    "            draw_index.append(i)\n",
    "    final_df['label_final'] = label_final\n",
    "    final_df.drop(draw_index, inplace=True)\n",
    "    final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "# Noted : Single Word, No Clean\n",
    "# final_df = clean_label_side(final_df) \n",
    "# display(final_df)\n",
    "\n",
    "# analyze accuracy per model\n",
    "CONFIDENCE_THRESHOLD = 0.8\n",
    "\n",
    "def analyze_model(final_df, confidence_threshold):\n",
    "    # get model names\n",
    "    model_names = [col.replace('_pred', '') for col in final_df.columns if '_pred' in col]\n",
    "    # display(model_names)\n",
    "\n",
    "    # iterate models\n",
    "    for model_name in model_names:\n",
    "        # copy data for specific model\n",
    "        model_df = final_df[['label_final', model_name+'_pred', model_name+'_conf']].copy()\n",
    "        # display(model_df)\n",
    "\n",
    "        # drop low confidence predictions\n",
    "        model_df.drop(\n",
    "            model_df.loc[\n",
    "                model_df[model_name+'_conf'] < confidence_threshold\n",
    "            ].index,\n",
    "            inplace=True\n",
    "        )\n",
    "\n",
    "        # analyze model\n",
    "        # print(model_name + '\\n' + '='*20)\n",
    "        labels = model_df['label_final'].to_list()\n",
    "        preds = model_df[model_name+'_pred']\n",
    "        # print('> Weighted F1 score')\n",
    "        print(f1_score(labels, preds, average='weighted'))\n",
    "        # print('> Per class F1 score')\n",
    "        # print(f1_score(labels, preds, average=None))\n",
    "        # print('> Confusion matrix')\n",
    "        # print(confusion_matrix(labels, preds, labels=['negative', 'neutral', 'positive']))\n",
    "        # print()\n",
    "        # print('> Confusion matrix (normalized)')\n",
    "        # display(confusion_matrix(labels, preds, labels=['negative', 'neutral', 'positive'], normalize='true'))\n",
    "        # display()\n",
    "        # print()\n",
    "analyze_model(final_df, CONFIDENCE_THRESHOLD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
